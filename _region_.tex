\message{ !name(review.tex)}\title{Statistics Review}
\author{Ricson}
\date{\today}
\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[expansion=false]{microtype}
\usepackage{lmodern}
\usepackage{hyperref}

\newcommand{\eq}[1]{\begin{align*}#1\end{align*}}
\newcommand{\enum}[1]{\begin{enumerate}#1\end{enumerate}}
\renewcommand{\list}[1]{\begin{itemize}#1\end{itemize}}

\begin{document}

\message{ !name(review.tex) !offset(-3) }

\maketitle

\tableofcontents

\newpage

\section{Probability Theory}

\subsection{Conjugate Priors}

\subsection{Basic manipulations of Multivariate Gaussians}

\subsection{Extremal Value Distributions}

\section{Information Theory}

\subsection{Basics}

\subsection{KL Divergence}

\subsection{Fisher Information Matrix}

\section{Linear Algebra}

\subsection{Identities}

\subsection{Singular Value Decomposition}

\subsection{Principle Component Analysis}

\section{Probabilistic Graphical Models}

\subsection{Viterbi and Forward Backward Algorithm}

\renewcommand{\o}{\mathbf{o}}
\newcommand{\x}{\mathbf{x}}

The key to deriving the forward backward algorithm for the linear-chain CRF is to realize that there is no fundamental difference between HMM and CRF.
The likelihood of a linear-chain CRF is defined to be the product of all the potentials. But before we get mixed up in math here: $o_i$ denotes observation and $x_i$ denotes the hidden state.

\eq{
P(\x) = \prod_i \phi(x_i) \prod_{i,i+1} \phi(x_i, x_{i+1})
}

On the other hand, the likelihood of the equivalent HMM model is the following:

\eq{
P(x) = \prod_i P(o_i | x_i) P(x_i | x_{i+1})
}
Note this product is incorrect when $i = n$, but let's ignore that.

Now if you squint really closely, you're realize that these two equations are actually the same thing. We can just replace $P(o_i|x_i)$ with $\phi(x_i)$ and $P(x_i|x_{i+1})$ with $\phi(x_i, x_{i+1})$. So it suffices to solve inference on the general setting of CRFs. However, we'll start on HMMs simply to avoid a bit of headaches.

We want to solve for $P(x_k|\o)$. The key is the following manipulation:

\eq{
  P(x_k|\o) &= \frac{P(\o|x_k)p(x_k)}{P(\o)} \\
  &\propto P(\o|x_k)p(x_k) \\
  &= P(\o_{1:k}|x_k)P(\o_{k+1:n}|x_k)P(x_k) \\
}

Let's take that second term and apply Bayes' Theorem again

\eq{
  P(\o_{k+1:n}|x_k) &= \frac{P(x_k | \o_{k+1:n}) P(\o_{k+1:n})}{P(x_k)} \\
  &\propto \frac{P(x_k | \o_{k+1:n})}{P(x_k)}
}

And substitute it back in...

\eq{
  P(\o_{1:k}|x_k)P(\o_{k+1:n}|x_k)P(x_k) &= P(\o_{1:k}|x_k)\frac{P(x_k | \o_{k+1:n})}{P(x_k)}P(x_k)\\
  &= P(\o_{1:k}|x_k)P(x_k | \o_{k+1:n})
}

So now we just need to figure out how to compute $P(\o_{1:k}|x_k)$ and $P(x_k|o_{k+1:n})$. We can do this inductively. To do this, we specify that each $x_i$ is a categorical variables in one of $m$ classes indexed by $j$. In the base case, we are given $P(o_1 | x_1)$. Since $x_k$ is between $o_{1:k-1}$ and $o_k$ it renders $o_k$ independent from the rest, conditioned on $x_k$. We will take advantage of this.

\eq{
  P(o_{1:k}|x_k) &= P(o_{1:k-1}|x_k)P(o_k|x_k) \\
  & = P(o_k|x_k) \sum_j P(o_{1:k-1}|x_{k-1} = j)p(x_{k-1} = j|x_k)
}

Notice that we can retrieve $P(o_{1:k-1}|x_{k-1})$ from a recursive case, so we have solved the problem.

Computing $P(x_k|o_{k+1:n})$ is very similar. We start with the base case that $P(x_{n-1}|o_n)$. I don't know how to do this...help

Question: what if we need to know $P(x_n)$? Well we won't, because if you look at our final equation $P(\o_{1:k}|x_k)P(x_k | \o_{k+1:n})$, if we have $k = n$, then the first term will contain everything we need and the second term will just be 1. 

Normalization is needed, because we did a lot of trickery with only dealing with $\propto$

\subsection{Message Passing and Loopy Belief Propagation}

\subsection{Efficient Inference in Dense Gaussian CRFS}

\section{Linear and Nonlinear Bayesian Models}

\subsection{Bayesian Linear Regression}

\subsubsection{Evidence Approximation}

\subsection{Bayesian Logistic Regression}

\subsubsection{Laplace Approximation}

\subsection{Spline and Wavelet Bases}

\subsection{Bayesian Neural Networks}
\section{Approximate Inference}

\subsection{Expectation Maximization}

\subsection{Variational Inference}

\section{Sampling Algorithms}

\subsection{Importance Sampling}

\subsection{Monte Carlo Markov Chain}

\subsubsection{Metropolis Hastings}

\subsubsection{Reversible Jump MCMC}

\subsection{Gibbs Sampling}

\section{Optimization}

\subsection{Lagrange Multipliers}

\subsection{Lagrangian Duality}

\subsection{KKT Conditions}

\subsection{SGD Variants}

\subsection{BADMM Algorithm}

\section{Reinforcement Learning}

\subsection{Optimal Control}

\subsubsection{LQR}

\subsubsection{MPC and ILQR}

\subsubsection{Stochastic Optimal Control}

\subsection{Policy Gradients}

\subsection{Natural Policy Gradients}

\subsection{Trust Region Policy Optimization}

\subsection{Guided Policy Search}

\subsection{End to End Deep Visuomotor Policies}

\section{Neural Networks}

\subsection{Variational Autoencoders}

\subsection{Architectures}

\subsubsection{Neural Turing Machine}

\subsubsection{Neural GPU}

\subsubsection{Grid LSTM}

\section{Miscellaneous}

\subsection{Matrix Differentials}

\subsection{Calculus of Variations}

\subsection{Echo State Networks}

\subsection{Gumbel Trick}

\subsection{Support Vector Machines}

\subsection{Gaussian Processes}

\subsection{Independent Component Analysis}

\end{document}

\message{ !name(review.tex) !offset(-208) }
